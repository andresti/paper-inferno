{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "ds = tf.contrib.distributions\n",
    "k = tf.keras\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"lines.color\": \"white\",\n",
    "    \"patch.edgecolor\": \"white\",\n",
    "    \"text.color\": \"black\",\n",
    "    \"axes.facecolor\": \"white\",\n",
    "    \"axes.edgecolor\": \"lightgray\",\n",
    "    \"axes.labelcolor\": \"white\",\n",
    "    \"xtick.color\": \"white\",\n",
    "    \"ytick.color\": \"white\",\n",
    "    \"grid.color\": \"lightgray\",\n",
    "    \"figure.facecolor\": \"#222222\",\n",
    "    \"figure.edgecolor\": \"#222222\",\n",
    "    \"savefig.facecolor\": \"#22222200\",\n",
    "    \"savefig.edgecolor\": \"#222222\",\n",
    "    \"font.size\": 20})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "ds = tf.contrib.distributions\n",
    "\n",
    "r_dist = tf.placeholder_with_default(2., shape=())\n",
    "\n",
    "bkg = ds.MultivariateNormalFullCovariance(loc=[r_dist, 0.],\n",
    "        covariance_matrix=[[5.,0.],[0.,9.]], name=\"p0\")\n",
    "\n",
    "sig = ds.MultivariateNormalDiag(loc=[0., 0.],\n",
    "        scale_diag=[1., 1.], name=\"p1\")\n",
    "\n",
    "mu = tf.placeholder(shape=(), dtype=tf.float32, name=\"mu\")\n",
    "mix = ds.Mixture(cat=ds.Categorical(probs=[1.-mu, mu]),\n",
    "               components = [bkg, sig])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = mix.sample(1020, seed=17)\n",
    "sig_sample = sig.sample(400, seed=17)\n",
    "bkg_sample = bkg.sample(400, seed=17)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    data_arr = sess.run(data_sample, feed_dict={mu : 20./1000.})\n",
    "    sig_arr = sess.run(sig_sample)\n",
    "    bkg_arr = sess.run(bkg_sample)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.scatter(data_arr[:,0],data_arr[:,1], color=\"black\", alpha=0.5, s=20)\n",
    "ax.set_xlabel(\"variable 1\")\n",
    "ax.set_ylabel(\"variable 2\")\n",
    "\n",
    "\n",
    "\n",
    "ax.set_ylim([-10,10])\n",
    "ax.set_xlim([-10,10])\n",
    "\n",
    "#fig.savefig(\"../../iml_workshop_talk/gfx/obs_data_example.svg\",\n",
    "#            bbox_inches='tight')\n",
    "\n",
    "fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.scatter(bkg_arr[:,0],bkg_arr[:,1], color=\"blue\", alpha=0.5, s=20, label=\"bkg simulation\")\n",
    "ax.scatter(sig_arr[:,0],sig_arr[:,1], color=\"red\", alpha=0.5,s=20, label=\"sig simulation\")\n",
    "\n",
    "ax.set_xlabel(\"variable 1\")\n",
    "ax.set_ylabel(\"variable 2\")\n",
    "\n",
    "\n",
    "\n",
    "ax.set_ylim([-10,10])\n",
    "ax.set_xlim([-10,10])\n",
    "\n",
    "ax.legend(loc=2)\n",
    "\n",
    "#fig.savefig(\"../../iml_workshop_talk/gfx/sim_data_example.svg\",\n",
    "#            bbox_inches='tight')\n",
    "\n",
    "fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scan  = np.linspace(-5.,5.,1001, endpoint=True, dtype=np.float32)\n",
    "y_scan  = np.linspace(-5.,5.,1001, endpoint=True, dtype=np.float32)\n",
    "\n",
    "X_grid = np.stack(np.meshgrid(x_scan, y_scan),axis=-1)\n",
    "grid_shape = list(X_grid.shape[:-1])\n",
    "X_flat = np.reshape(X_grid, [-1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grid_t = tf.placeholder(shape=(None, None, 2), dtype=tf.float32)\n",
    "\n",
    "mix_grid = mix.log_prob(X_grid_t)\n",
    "bkg_grid = bkg.log_prob(X_grid_t)\n",
    "sig_grid = sig.log_prob(X_grid_t)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    mix_grid_arr = sess.run(mix_grid, feed_dict={X_grid_t : X_grid, mu : 0.2})\n",
    "    bkg_grid_arr = sess.run(bkg_grid, feed_dict={X_grid_t : X_grid})\n",
    "    sig_grid_arr =  sess.run(sig_grid, feed_dict={X_grid_t : X_grid})\n",
    "    \n",
    "\n",
    "lr_mix_bkg = mix_grid_arr - bkg_grid_arr\n",
    "lr_sig_bkg = sig_grid_arr - bkg_grid_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 125000\n",
    "X_sample_tensors = {}\n",
    "y_values = {}\n",
    "p0_sample = \"p0_sample\"\n",
    "X_sample_tensors[p0_sample] = bkg.sample(n_samples // 2, seed=7, name=\"sig_sample\") \n",
    "y_values[p0_sample] = 0.\n",
    "p1_sample = \"p1_sample\"\n",
    "X_sample_tensors[p1_sample] = sig.sample(n_samples // 2, seed=17, name=\"bkg_sample\") \n",
    "y_values[p1_sample] = 1.\n",
    "\n",
    "samples = {}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for name, sample_tensor in X_sample_tensors.items():\n",
    "        samples[name] = {}\n",
    "        samples[name][\"X\"] = sess.run(sample_tensor)\n",
    "        samples[name][\"y\"] =  y_values[name]*np.ones(sample_tensor.shape[0],\n",
    "                                                     dtype=np.float32)\n",
    "train_samples = {}\n",
    "valid_samples = {}\n",
    "\n",
    "for name,sample in samples.items():\n",
    "    keys = sample.keys()\n",
    "    split_sample = train_test_split(*list(sample.values()),\n",
    "                                    test_size = 0.4,\n",
    "                                    random_state=17)\n",
    "    train_samples[name] = { k : split_sample[i] for k,i in zip(keys,[0,2])}\n",
    "    valid_samples[name] = { k : split_sample[i] for k,i in zip(keys,[1,3])}\n",
    "    \n",
    "\n",
    "X_train = np.concatenate([s[\"X\"] for s in train_samples.values()] )\n",
    "y_train = np.concatenate([s[\"y\"] for s in train_samples.values()] )\n",
    "X_valid = np.concatenate([s[\"X\"] for s in valid_samples.values()] )\n",
    "y_valid = np.concatenate([s[\"y\"] for s in valid_samples.values()] )\n",
    "\n",
    "i_train = np.arange(y_train.shape[0])\n",
    "np.random.shuffle(i_train)\n",
    "\n",
    "X_train = X_train[i_train]\n",
    "y_train = y_train[i_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = k.Sequential()\n",
    "activation = \"relu\" \n",
    "initializer = \"glorot_normal\" \n",
    "model.add(k.layers.Dense(10, activation=activation,\n",
    "            kernel_initializer=initializer,\n",
    "        name=\"dense_0\", input_shape=(2,)))\n",
    "model.add(k.layers.Dense(10, activation=activation,\n",
    "          kernel_initializer=initializer,\n",
    "          name=\"dense_1\"))\n",
    "model.add(k.layers.Dense(1, activation=\"sigmoid\", name=\"output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = k.optimizers.SGD(lr=0.01)\n",
    "model.compile(optim,\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = k.models.load_model(\"keras_bce_SGD_lr_0p01_100_epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=50,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = np.reshape(X_grid, [-1,2])\n",
    "y_flat = model.predict(X_flat, batch_size=1024)\n",
    "y_grid = np.reshape(y_flat, grid_shape)\n",
    "\n",
    "lr_nn_approx =  np.log(y_grid)-np.log(1.-y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "fig, axs = plt.subplots(1,3,figsize=(30,8))\n",
    "\n",
    "titles = [r\"Analytical $\\ln(p(x|H_1)/p(x|H_0))$\",\n",
    "          r\"Analytical $\\ln(p_s(x)/p_b(x))$\",\n",
    "          r\"DNN approximation $\\ln(p_s(x)/p_b(x))$\"]\n",
    "levels = [None,\n",
    "          np.linspace(-21,3,9,endpoint=True),\n",
    "          np.linspace(-21,3,9,endpoint=True)]\n",
    "\n",
    "for i,lr in enumerate([lr_mix_bkg, lr_sig_bkg, lr_nn_approx]):\n",
    "    con = axs[i].contourf(x_scan, y_scan, lr, levels=levels[i])\n",
    "    fig.colorbar(con, ax=axs[i],)\n",
    "    axs[i].set_xlabel(\"variable 1\")\n",
    "    axs[i].set_ylabel(\"variable 2\")\n",
    "    axs[i].set_title(titles[i],color='white')\n",
    "    axs[i].set_ylim([-5,5])\n",
    "    axs[i].set_xlim([-5,5])\n",
    "    \n",
    "#fig.savefig(\"../../iml_workshop_talk/gfx/clf_lr_approximation.svg\",transparent=True,bbox_inches='tight')\n",
    "fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_pred = model.predict_proba(valid_samples[\"p0_sample\"][\"X\"])\n",
    "sig_pred = model.predict(valid_samples[\"p1_sample\"][\"X\"])\n",
    "\n",
    "dat_pred = model.predict_proba(data_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "bins = np.linspace(0., 1., 11, endpoint=True)\n",
    "bkg_hist,_ = np.histogram(bkg_pred,bins=bins,density=True)\n",
    "sig_hist,_ = np.histogram(sig_pred,bins=bins,density=True)\n",
    "dat_hist,_ = np.histogram(dat_pred,bins=bins)\n",
    "\n",
    "width = bins[:-1] - bins[1:]\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "\n",
    "#ax.bar(center, dat_hist, align='center', width=width)\n",
    "bkg_normed = 1000.*bkg_hist/bkg_hist.sum()\n",
    "sig_normed = 20.*sig_hist/sig_hist.sum()\n",
    "bkg_bar = ax.bar(center, bkg_normed, align='center', color=\"blue\", alpha=0.5, width=width, label=\"background\")\n",
    "sig_bar = ax.bar(center, sig_normed, align='center', color=\"red\", bottom=bkg_normed, alpha=0.5, width=width, label=\"signal\")\n",
    "dat_bar = ax.errorbar(center, dat_hist, yerr=np.sqrt(dat_hist),fmt='k.', capsize=4, elinewidth=2, label=\"data\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"NN classifier output per event\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "ax.set_xlim([0.,1.])\n",
    "ax.set_facecolor(\"white\")\n",
    "\n",
    "#fig.savefig(\"../../iml_workshop_talk/gfx/clf_sig_bkg_data.svg\",bbox_inches='tight',edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = np.array([[1.,0.]])\n",
    "bkg_pred_up = model.predict_proba(valid_samples[\"p0_sample\"][\"X\"]+shift)\n",
    "bkg_pred_dw = model.predict_proba(valid_samples[\"p0_sample\"][\"X\"]-shift)\n",
    "\n",
    "bins = np.linspace(0., 1., 11, endpoint=True)\n",
    "bkg_hist,_ = np.histogram(bkg_pred,bins=bins,density=True)\n",
    "bkg_hist_up,_ = np.histogram(bkg_pred_up,bins=bins,density=True)\n",
    "bkg_hist_dw,_ = np.histogram(bkg_pred_dw,bins=bins,density=True)\n",
    "sig_hist,_ = np.histogram(sig_pred,bins=bins,density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neyman.inferences as ni\n",
    "import neyman.models as nm\n",
    "\n",
    "\n",
    "def int_quad_lin(alpha, c_nom, c_up, c_dw):\n",
    "    \"Three-point interpolation, quadratic inside and linear outside\"\n",
    "    \n",
    "    alpha_t = tf.tile(tf.expand_dims(alpha,axis=-1),[1, tf.shape(c_nom)[0]])\n",
    "    a = 0.5*(c_up+c_dw)-c_nom\n",
    "    b = 0.5*(c_up-c_dw)\n",
    "    ones = tf.ones_like(alpha_t)\n",
    "    switch = tf.where(alpha_t < 0.,\n",
    "                      ones*tf.expand_dims(c_dw-c_nom, axis=0),\n",
    "                      ones*tf.expand_dims(c_up-c_nom, axis=0))\n",
    "    abs_var = tf.where(tf.abs(alpha_t) > 1., \n",
    "                      (2*b+tf.sign(alpha_t)*a)*(alpha_t-tf.sign(alpha_t))+switch,\n",
    "                      a*tf.pow(alpha_t,2)+b*alpha_t)\n",
    "    return c_nom+abs_var\n",
    "\n",
    "def poisson(x, rate):\n",
    "    \"float64  poisson pdf (avoid numerical inacurracies)\"\n",
    "    x_d = tf.cast(x, tf.float64)\n",
    "    rate_d = tf.cast(rate, tf.float64)\n",
    "    log_rate_d = tf.log(rate_d)\n",
    "    p_d = x_d*log_rate_d - tf.lgamma(tf.convert_to_tensor(1.,dtype=tf.float64)+x_d)-rate_d\n",
    "    return tf.cast( p_d, tf.float32)\n",
    "\n",
    "# expected shapes for background (nom/up/down variation for interpolation)\n",
    "c_bkg_nom_ph = tf.placeholder(dtype=tf.float32, shape=(None,), name=\"c_bkg_nom_ph\") \n",
    "c_bkg_dw_ph = tf.placeholder(dtype=tf.float32, shape=(None,), name=\"c_bkg_dw_ph\") \n",
    "c_bkg_up_ph = tf.placeholder(dtype=tf.float32, shape=(None,), name=\"c_bkg_up_ph\") \n",
    "# expected shapes for signal (no parameters)\n",
    "c_sig_ph = tf.placeholder(dtype=tf.float32, shape=(None,), name=\"c_sig_ph\")\n",
    "\n",
    "# expected number of signal and background events\n",
    "n_bkg_ph = tf.placeholder_with_default(10000., shape=(), name=\"n_bkg_ph\")\n",
    "n_sig_ph = tf.placeholder_with_default(100., shape=(), name=\"n_sig_ph\")\n",
    "\n",
    "# model parameters (input specified by placeholders)\n",
    "mu_ph = tf.placeholder(dtype=tf.float32, shape=(None,), name=\"mu_ph\")\n",
    "r_dist_ph = tf.placeholder(dtype=tf.float32, shape=(None,), name=\"r_dist_ph\")\n",
    "\n",
    "# auxiliary measurement parameters\n",
    "r_dist_scale_ph = tf.placeholder_with_default(0.2, shape=(), name=\"theta_scale_ph\")\n",
    "\n",
    "# distribution of nuissance parameters\n",
    "r_dist_rv = nm.Normal(loc=tf.ones_like(r_dist_ph)*2.0,\n",
    "                      scale=tf.ones_like(r_dist_ph)*r_dist_scale_ph,\n",
    "                      value=r_dist_ph,\n",
    "                      name=\"r_dist_dist\")\n",
    "\n",
    "# background shape as a function of r_dist\n",
    "c_bkg = int_quad_lin((r_dist_rv-2.0)/r_dist_scale_ph, c_bkg_nom_ph,\n",
    "                     c_bkg_up_ph, c_bkg_dw_ph)\n",
    "\n",
    "# expected events ([batch, bin])\n",
    "mu = tf.expand_dims(mu_ph,-1, name=\"mu_expanded\")\n",
    "expected = mu*n_sig_ph*c_sig_ph+n_bkg_ph*c_bkg\n",
    "\n",
    "# placeholder for data/asimov\n",
    "observed_ph = tf.placeholder(dtype=tf.float32, shape=(None,), name=\"observed_ph\")\n",
    "\n",
    "# likelihood\n",
    "poisson_pdf = poisson(observed_ph, expected)\n",
    "nll = -tf.reduce_sum(poisson_pdf ,-1)\n",
    "r_dist_ext = -r_dist_rv.log_prob(r_dist_rv)\n",
    "nll_ext = nll+r_dist_ext \n",
    "\n",
    "# hessians and likelihoods\n",
    "h_nll, g_nll =  ni.batch_hessian(nll, pars=[mu_ph, r_dist_rv])\n",
    "h_nll_ext, g_nll_ext = ni.batch_hessian(nll_ext, pars=[mu_ph, r_dist_rv])\n",
    "\n",
    "# covariance without constraints (only POI)\n",
    "c_nll_poi = tf.matrix_inverse(h_nll[:,:1,:1], name=\"c_nll_poi\")\n",
    "c_nll = tf.matrix_inverse(h_nll, name=\"c_nll\")\n",
    "c_nll_ext = tf.matrix_inverse(h_nll_ext, name=\"c_nll_ext\")\n",
    "# profile grads and hess (only nuissance par)\n",
    "g_nll_prof = g_nll_ext[:,1:]\n",
    "h_nll_prof = h_nll_ext[:,1:,1:]\n",
    "c_nll_prof = tf.matrix_inverse(h_nll_prof, name=\"c_nll_prof\")\n",
    "\n",
    "# newton step\n",
    "newton_step =  tf.matmul(c_nll_prof, g_nll_prof[:,:, tf.newaxis])[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_phs = {c_bkg_nom_ph : bkg_hist/bkg_hist.sum(),\n",
    "             c_bkg_dw_ph : bkg_hist_dw/bkg_hist_dw.sum(),\n",
    "             c_bkg_up_ph : bkg_hist_up/bkg_hist_up.sum(),\n",
    "             c_sig_ph : sig_hist/sig_hist.sum()}\n",
    "\n",
    "norm_phs = {n_bkg_ph : 1000.,\n",
    "            n_sig_ph : 40.}\n",
    "\n",
    "par_phs = {mu_ph : [1.]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_phs = {mu_ph : [1.],\n",
    "           r_dist_rv: [2.]}\n",
    "\n",
    "feed_dict = {**shape_phs, **norm_phs, **par_phs}\n",
    "\n",
    "minima = {}\n",
    "with tf.Session() as sess:\n",
    "    asimov_data = sess.run(expected, feed_dict=feed_dict)\n",
    "    print(\"asimov data: \", asimov_data[0])\n",
    "    asimov_phs = {observed_ph : asimov_data[0]}\n",
    "    feed_dict = {**feed_dict, **asimov_phs}\n",
    "    minima  = sess.run({ t : t for t in [c_nll_ext, c_nll_poi, g_nll_ext ] }, feed_dict=feed_dict)\n",
    "\n",
    "print(\"error mu no nuis:\", np.sqrt(np.diag(minima[c_nll_poi][0])))\n",
    "print(\"error mu and nuis:\", np.sqrt(np.diag(minima[c_nll_ext][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mu_scan = np.linspace(0.02,1.98, 101, endpoint=True, dtype=np.float32)\n",
    "par_phs = {mu_ph : mu_scan,\n",
    "           r_dist_ph: np.ones_like(mu_scan)*2.}\n",
    "\n",
    "feed_dict = {**shape_phs, **norm_phs, **par_phs, **asimov_phs}\n",
    "\n",
    "no_nuis = {}\n",
    "profiled = {}\n",
    "with tf.Session() as sess:\n",
    "    no_nuis[nll_ext] = sess.run(nll_ext, feed_dict=feed_dict)\n",
    "    feed_dict[r_dist_ph] = feed_dict[r_dist_ph]\n",
    "    for i in range(10):\n",
    "        newton_step_arr = sess.run(newton_step , feed_dict=feed_dict)\n",
    "        feed_dict[r_dist_ph] =  feed_dict[r_dist_ph]-newton_step_arr\n",
    "    profiled[nll_ext] = sess.run(nll_ext, feed_dict=feed_dict)\n",
    "\n",
    "direct_lr_no_nuis = no_nuis[nll_ext]\n",
    "direct_lr_nuis = profiled[nll_ext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_lr_no_nuis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, figsize=(14,16))\n",
    "\n",
    "\n",
    "ax = axs[0]\n",
    "width = bins[:-1] - bins[1:]\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "ax.bar(center, sig_hist, align='center', width=width, label=\"signal\",\n",
    "       fill=None,linewidth=2.5, linestyle='-',edgecolor='red' )\n",
    "\n",
    "ax.bar(center, bkg_hist_up, align='center',width=width, label=\"bkg shift up\",\n",
    "       fill=None, linewidth=2.5, linestyle='--',edgecolor='darkorange')\n",
    "ax.bar(center, bkg_hist, align='center', color=\"blue\", alpha=0.5, width=width, label=\"bkg nom\",\n",
    "       fill=None,linewidth=2.5, linestyle='-',edgecolor='blue')\n",
    "ax.bar(center, bkg_hist_dw, align='center', width=width, label=\"bkg shift dw\",\n",
    "       fill=None,linewidth=2.5, linestyle='--',edgecolor='green')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlim([0.,1.])\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"NN classifier output per event\")\n",
    "ax.set_ylabel(\"density\")\n",
    "\n",
    "\n",
    "ax = axs[1]\n",
    "\n",
    "ax.plot(mu_scan, no_nuis[nll_ext]-no_nuis[nll_ext].min(),\n",
    "        color=\"green\",label=\"without nuissance pars\")\n",
    "ax.plot(mu_scan, profiled[nll_ext]-profiled[nll_ext].min(),\n",
    "        color=\"red\",label=\"with nuissance pars (profiled)\")\n",
    "\n",
    "ax.hlines(y=0.5, xmin=0., xmax=2., linestyles='dashed')\n",
    "ax.set_xlabel(\"parameter of interest $\\mu$\")\n",
    "ax.set_ylabel(\"$\\Delta(\\mathcal{-\\ln L})$\")\n",
    "\n",
    "ax.set_xlim([0.3,1.7])\n",
    "ax.set_ylim([-0.05,1.25])\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "#fig.savefig(\"../../iml_workshop_talk/gfx/clf_systematic_effect.svg\",bbox_inches='tight',edgecolor='none')\n",
    "\n",
    "\n",
    "fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mu_scan = np.linspace(0.3,1.6, 101, endpoint=True, dtype=np.float32)\n",
    "r_dist_scan = np.linspace(1.95,2.05, 101, endpoint=True, dtype=np.float32)\n",
    "par_phs = {mu_ph : [1],\n",
    "           theta_ph: [0.0],\n",
    "           r_dist_ph: r_dist_scan}\n",
    "\n",
    "feed_dict = {**shape_phs, **norm_phs, **par_phs, **asimov_phs}\n",
    "\n",
    "nll_surface = np.empty([mu_scan.shape[0],r_dist_scan.shape[0]], dtype=np.float32)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i, mu_val in enumerate(mu_scan):\n",
    "        feed_dict[mu_ph] = [mu_val]\n",
    "        nll_surface[i] = sess.run(nll_ext, feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "#im = ax.imshow(nll_surface)\n",
    "pcm = ax.contourf(r_dist_scan,mu_scan,nll_surface-nll_surface.min(), levels=list(np.linspace(0.,6.,13,endpoint=True)))\n",
    "fig.colorbar(pcm, ax=ax)\n",
    "ax.set_title(\"$\\Delta(\\mathcal{-\\ln L})$ surface\", color=\"white\")\n",
    "\n",
    "ax.set_xlabel(\"nuisance parameter (bkg mean)\")\n",
    "ax.set_ylabel(\"parameter of interest $\\mu$\")\n",
    "\n",
    "#fig.savefig(\"../../iml_workshop_talk/gfx/likelihood_ratio_learning.svg\",bbox_inches='tight',edgecolor='none')\n",
    "\n",
    "fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dist_scan = np.linspace(1.8,2.2, 101, endpoint=True, dtype=np.float32)\n",
    "par_phs = {mu_ph : [1.0],\n",
    "           theta_ph: [0.0],\n",
    "           r_dist_ph : r_dist_scan}\n",
    "\n",
    "feed_dict = {**shape_phs, **norm_phs, **par_phs, **asimov_phs}\n",
    "\n",
    "arrs = {}\n",
    "with tf.Session() as sess:\n",
    "    feed_dict = {**feed_dict, **asimov_phs}\n",
    "    arrs[r_dist_ext]= sess.run(r_dist_ext, feed_dict=feed_dict)\n",
    "    arrs[nll_ext] = sess.run(nll_ext, feed_dict=feed_dict)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.plot(r_dist_scan, arrs[r_dist_ext]-arrs[r_dist_ext].min(), color=\"blue\")\n",
    "ax.plot(r_dist_scan, arrs[nll_ext]-arrs[nll_ext].min(),color=\"red\")\n",
    "\n",
    "ax.set_ylim([-0.1, 1.0])\n",
    "fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = k.models.load_model(\"shift_0.2_n_bins_2_bs_512_lr_0.0001.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scan  = np.linspace(-5.,5.,1001, endpoint=True, dtype=np.float32)\n",
    "y_scan  = np.linspace(-5.,5.,1001, endpoint=True, dtype=np.float32)\n",
    "\n",
    "X_grid = np.stack(np.meshgrid(x_scan, y_scan),axis=-1)\n",
    "grid_shape = list(X_grid.shape[:-1])\n",
    "X_flat = np.reshape(X_grid, [-1,2])\n",
    "\n",
    "X_flat = np.reshape(X_grid, [-1,2])\n",
    "y_flat = model.predict(X_flat, batch_size=1024)\n",
    "y_grid = np.reshape(y_flat, grid_shape+[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_pred = model.predict_proba(valid_samples[\"p0_sample\"][\"X\"])[:,1]\n",
    "sig_pred = model.predict(valid_samples[\"p1_sample\"][\"X\"])[:,1]\n",
    "\n",
    "dat_pred = model.predict_proba(data_arr)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "bins = np.linspace(0., 0.4, 5, endpoint=True)\n",
    "bkg_hist,_ = np.histogram(bkg_pred,bins=bins,density=True)\n",
    "sig_hist,_ = np.histogram(sig_pred,bins=bins,density=True)\n",
    "dat_hist,_ = np.histogram(dat_pred,bins=bins)\n",
    "\n",
    "width = bins[:-1] - bins[1:]\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "\n",
    "#ax.bar(center, dat_hist, align='center', width=width)\n",
    "bkg_normed = 1000.*bkg_hist/bkg_hist.sum()\n",
    "sig_normed = 20.*sig_hist/sig_hist.sum()\n",
    "bkg_bar = ax.bar(center, bkg_normed, align='center', color=\"blue\", alpha=0.5, width=width, label=\"background\")\n",
    "sig_bar = ax.bar(center, sig_normed, align='center', color=\"red\", bottom=bkg_normed, alpha=0.5, width=width, label=\"signal\")\n",
    "dat_bar = ax.errorbar(center, dat_hist, yerr=np.sqrt(dat_hist),fmt='k.', capsize=4, elinewidth=2, label=\"data\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"NN classifier output per event\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "ax.set_xlim([0.,0.4])\n",
    "ax.set_facecolor(\"white\")\n",
    "\n",
    "#fig.savefig(\"../../iml_workshop_talk/gfx/clf_sig_bkg_data.svg\",bbox_inches='tight',edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = np.array([[1.,0.]])\n",
    "bkg_pred_up = model.predict_proba(valid_samples[\"p0_sample\"][\"X\"]+shift)\n",
    "bkg_pred_dw = model.predict_proba(valid_samples[\"p0_sample\"][\"X\"]-shift)\n",
    "\n",
    "bins = np.linspace(0., 0.4, 5, endpoint=True)\n",
    "bkg_hist,_ = np.histogram(bkg_pred,bins=bins,density=True)\n",
    "bkg_hist_up,_ = np.histogram(bkg_pred_up,bins=bins,density=True)\n",
    "bkg_hist_dw,_ = np.histogram(bkg_pred_dw,bins=bins,density=True)\n",
    "sig_hist,_ = np.histogram(sig_pred,bins=bins,density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_phs = {c_bkg_nom_ph : bkg_hist/bkg_hist.sum(),\n",
    "             c_bkg_dw_ph : bkg_hist_dw/bkg_hist_dw.sum(),\n",
    "             c_bkg_up_ph : bkg_hist_up/bkg_hist_up.sum(),\n",
    "             c_sig_ph : sig_hist/sig_hist.sum()}\n",
    "\n",
    "norm_phs = {n_bkg_ph : 1000.,\n",
    "            n_sig_ph : 40.}\n",
    "\n",
    "par_phs = {mu_ph : [1.]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_phs = {mu_ph : [1.],\n",
    "           r_dist_rv: [2.]}\n",
    "\n",
    "feed_dict = {**shape_phs, **norm_phs, **par_phs}\n",
    "\n",
    "minima = {}\n",
    "with tf.Session() as sess:\n",
    "    asimov_data = sess.run(expected, feed_dict=feed_dict)\n",
    "    print(\"asimov data: \", asimov_data[0])\n",
    "    asimov_phs = {observed_ph : asimov_data[0]}\n",
    "    feed_dict = {**feed_dict, **asimov_phs}\n",
    "    minima  = sess.run({ t : t for t in [c_nll_ext, c_nll_poi, g_nll_ext ] }, feed_dict=feed_dict)\n",
    "\n",
    "print(\"error mu no nuis:\", np.sqrt(np.diag(minima[c_nll_poi][0])))\n",
    "print(\"error mu and nuis:\", np.sqrt(np.diag(minima[c_nll_ext][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_scan = np.linspace(0.02,1.98, 101, endpoint=True, dtype=np.float32)\n",
    "par_phs = {mu_ph : mu_scan,\n",
    "           r_dist_ph: np.ones_like(mu_scan)*2.}\n",
    "\n",
    "feed_dict = {**shape_phs, **norm_phs, **par_phs, **asimov_phs}\n",
    "\n",
    "no_nuis = {}\n",
    "profiled = {}\n",
    "with tf.Session() as sess:\n",
    "    no_nuis[nll_ext] = sess.run(nll_ext, feed_dict=feed_dict)\n",
    "    feed_dict[r_dist_ph] = feed_dict[r_dist_ph]\n",
    "    for i in range(10):\n",
    "        newton_step_arr = sess.run(newton_step , feed_dict=feed_dict)\n",
    "        feed_dict[r_dist_ph] =  feed_dict[r_dist_ph]-newton_step_arr\n",
    "    profiled[nll_ext] = sess.run(nll_ext, feed_dict=feed_dict)\n",
    "\n",
    "new_lr_no_nuis = no_nuis[nll_ext]\n",
    "new_lr_nuis = profiled[nll_ext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "title= r\"log decision surface (n_bins=2)\"\n",
    "level= np.linspace(-5.,0.,11,endpoint=True)\n",
    "\n",
    "\n",
    "ax.plot(mu_scan,direct_lr_no_nuis-direct_lr_no_nuis.min(),\"--\",\n",
    "        color=\"green\",label=\"classification: without nuissance pars\")\n",
    "ax.plot(mu_scan, direct_lr_nuis-direct_lr_nuis.min(),\"--\",\n",
    "        color=\"red\",label=\"classification: with nuissance pars\")\n",
    "ax.plot(mu_scan,new_lr_no_nuis-new_lr_no_nuis.min(),\n",
    "        color=\"green\",label=\"direct: without nuissance pars\")\n",
    "ax.plot(mu_scan, new_lr_nuis-new_lr_nuis.min(),\n",
    "        color=\"red\",label=\"direct: with nuissance pars\")\n",
    "\n",
    "ax.hlines(y=0.5, xmin=0., xmax=2., linestyles='dashed')\n",
    "\n",
    "ax.set_xlabel(\"parameter of interest $\\mu$\")\n",
    "ax.set_title(\"Profile Likelihood\", color=\"white\")\n",
    "ax.set_ylabel(\"$\\Delta(\\mathcal{-\\ln L})$\")\n",
    "\n",
    "ax.set_xlim([0.2,1.8])\n",
    "ax.set_ylim([-0.05,1.25])\n",
    "\n",
    "ax.legend()\n",
    "fig.savefig(\"../../iml_workshop_talk/gfx/profile_likelihood_comparison.svg\",bbox_inches='tight',edgecolor='none')\n",
    "\n",
    "\n",
    "fig;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
